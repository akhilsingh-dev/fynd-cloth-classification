{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"colab":{"name":"fashion-classifier-Dec02-1200.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YslnlJ6ODS-O","colab_type":"code","outputId":"e03dc5de-5ca8-4ca5-cafc-bf41242797d7","executionInfo":{"status":"ok","timestamp":1575964745132,"user_tz":-330,"elapsed":43344,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":130}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zpcN_y7--0uh","colab_type":"code","outputId":"4f7ab7d2-369b-454f-c3ee-5683b72db606","executionInfo":{"status":"ok","timestamp":1575964745138,"user_tz":-330,"elapsed":5884,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":65}},"source":["from IPython.display import SVG\n","import argparse, sys,os,datetime\n","import tensorflow.keras"],"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"IqMNpmCD-0ur","colab_type":"code","colab":{}},"source":["from matplotlib import image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy import ndimage\n","import scipy.misc\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x6YtugAJ-0uy","colab_type":"code","outputId":"02b9c7ea-f9c9-4483-d9a0-c94bee7e64ff","executionInfo":{"status":"ok","timestamp":1575964745141,"user_tz":-330,"elapsed":4992,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.python.framework import ops\n","from tensorflow.keras.preprocessing import image\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g4GZ-a0s-0va","colab_type":"code","colab":{}},"source":["from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,BatchNormalization\n","from tensorflow.keras.layers import Activation,Flatten,GlobalAveragePooling2D\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.optimizers import SGD,Adam\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard,ReduceLROnPlateau\n","from tensorflow.keras.applications import MobileNetV2 \n","import datetime\n","from tensorflow.losses import softmax_cross_entropy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVRECZXr-0u7","colab_type":"code","colab":{}},"source":["\n","##Setting paths to all directories...\n","\n","TRAIN_DIR=\"/content/gdrive/My Drive/Colab Notebooks/Train Directory\"\n","VAL_DIR=\"/content/gdrive/My Drive/Colab Notebooks/Val Directory\"\n","TEST_DIR=\"/content/gdrive/My Drive/Colab Notebooks/Test Directory\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aBCf2nP_-0vD","colab_type":"code","outputId":"28285e89-75be-4925-b767-688252c76988","executionInfo":{"status":"ok","timestamp":1575964747779,"user_tz":-330,"elapsed":4020,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":74}},"source":["\n","##generating a map of all the labels through the directory names...\n","\n","labels={}\n","x=0\n","print(os.listdir(TRAIN_DIR))\n","\n","for p in os.listdir(TRAIN_DIR):\n","    labels[x]=p\n","    x+=1\n","print(labels)\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["['polka dots', 'Patterned', 'floral', 'graphic', 'Checked', 'Colourblock', 'solid', 'Melange', 'Printed', 'abstract', 'striped', 'typography']\n","{0: 'polka dots', 1: 'Patterned', 2: 'floral', 3: 'graphic', 4: 'Checked', 5: 'Colourblock', 6: 'solid', 7: 'Melange', 8: 'Printed', 9: 'abstract', 10: 'striped', 11: 'typography'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NJ5ktmn4-0vI","colab_type":"code","colab":{}},"source":["## defining a \"feeder\" to take batches of images of size \"batch\" to augment and feed the DL model...\n","def feeder(batch,targetSize):\n","    \n","    #take the image,flip it, scale brightness between 0.8 to 1.2 and finally rescale all images with range...\n","    #find the rescale value as per the ndarray dtype generated...\n","    \n","    #perform basic augmentation to increase the DL model's inputs...\n","    \n","    trainAugmenter = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8, 1.2],height_shift_range=0.1,width_shift_range=0.1,zoom_range=0.2,rescale=1./255)\n","    testAugmenter = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8, 1.2],height_shift_range=0.1,width_shift_range=0.1,zoom_range=0.2,rescale=1./255)\n","        \n","    \n","    #augmentation done...moving to create a flow from the directory for both train and test data...\n","    \n","    trainGen = trainAugmenter.flow_from_directory(TRAIN_DIR,shuffle=True,target_size=targetSize,\n","                                                  batch_size=batch,class_mode='categorical')\n","    \n","    testGen = testAugmenter.flow_from_directory(VAL_DIR,shuffle=True,target_size=targetSize,\n","                                               batch_size=batch,class_mode='categorical')\n","    \n","    \n","    #return a dictionary with both train and test generator objects...\n","    \n","    return {\"train\":trainGen,\n","            \"val\":testGen }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dva8Eqvk-0vO","colab_type":"code","outputId":"4e1761b7-5396-41f8-dd9b-afa6eab91573","executionInfo":{"status":"ok","timestamp":1575964792238,"user_tz":-330,"elapsed":42934,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["\n","##Defining the size of the image...\n","\n","imageWidth  = 600//1\n","imageHeight = 800//1\n","imageChannel = 3\n","batch=32\n","\n","##generating a flow with given params...\n","data = feeder(batch,(imageHeight,imageWidth))\n","train = data[\"train\"]\n","\n","\n","\n","#the test files have to be labelled for flow to work...\n","\n","\n","X_train, Y_train=train.next()\n","\n","#[TODO] : label the files in their respective directories... \n","#uncomment this after the TODO is done...\n","#[DONE] : split training into training and validation 0.9 to 0.1...\n","\n","\n","val = data[\"val\"]\n","X_val, Y_val=val.next()"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found 2927 images belonging to 12 classes.\n","Found 444 images belonging to 12 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LPmqZ1W8-0vT","colab_type":"code","outputId":"221d3f21-33ff-42d7-a8eb-07854b698fa8","executionInfo":{"status":"ok","timestamp":1575474048857,"user_tz":-330,"elapsed":9519,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":900}},"source":["#checking if the labels are correct or not\n","plt.imshow(X_train[2])\n","print(Y_train)\n","print(np.argmax(Y_train[2]))\n","print(labels[np.argmax(Y_train[2])])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n","9\n","abstract\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAMsAAAD8CAYAAADZhFAmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXdq+s+zbvu3S9p1l3/Ztl/b/AFbsLXknnL9HAAAAAElFTkSuQmCC\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Ajp_CJiS-0vZ","colab_type":"text"},"source":["The loading and augmentation part of the data is complete. We now move on to building the model..."]},{"cell_type":"code","metadata":{"id":"-8iihwVJ-0ve","colab_type":"code","colab":{}},"source":["inputDims = (imageHeight,imageWidth,3)\n","\n","def create_model():\n","    model=Sequential()\n","    \n","    model.add(Conv2D(64,kernel_size=(5,5),\n","                     strides=(2,2),input_shape=inputDims))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(Dropout(0.1))\n","    \n","    \n","\n","    model.add(Conv2D(64,kernel_size=(5,5),\n","                     strides=(2,2),input_shape=inputDims))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(Dropout(0.1))\n","    \n","    \n","    model.add(MaxPooling2D())\n","    \n","    model.add(Conv2D(64,kernel_size=(5,5),\n","                     strides=(2,2),input_shape=inputDims))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(MaxPooling2D())\n","    model.add(Dropout(0.1))\n","    \n","    #changing 128 to 64...\n","    model.add(Conv2D(64,kernel_size=(3,3),\n","                     strides=(2,2),input_shape=inputDims))\n","    model.add(LeakyReLU(alpha=0.05))\n","    #model.add(MaxPooling2D(pool_size=(3,3)))\n","    model.add(Dropout(0.2))\n","    \n","    #add 4th layer...\n","    model.add(Conv2D(64,kernel_size=(3,3),\n","                     strides=(2,2),input_shape=inputDims))\n","    model.add(LeakyReLU(alpha=0.05))\n","    #model.add(MaxPooling2D(pool_size=(3,3)))\n","    model.add(Dropout(0.2))\n","    \n","    \n","    \n","    model.add(BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001))\n","    \n","    \n","    \n","    model.add(Flatten())\n","    \n","    model.add(Dense(64))\n","    model.add(Activation(\"relu\"))\n","    model.add(Dropout(0.3))\n","    \n","    model.add(Dense(32))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(Dropout(0.2))\n","    \n","    model.add(Dense(12))\n","    model.add(Activation(\"softmax\"))\n","    \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHOXwmKf-0vl","colab_type":"code","colab":{}},"source":["def train_model(model):\n","    \n","    model.compile(loss=categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\n","    \n","    lrReducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.001)\n","    \n","    chkpt_dir = \"/content/gdrive/My Drive/Colab Notebooks/chkpts\"\n","    checkpointer = ModelCheckpoint(monitor='val_acc',filepath=os.path.join(chkpt_dir,\"4-3-weights2.hdf5\"), \n","                                   verbose=1, save_best_only=True)\n","    \n","    log_dir=\"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","    \n","    model.fit_generator(train,epochs=10,validation_data=val,callbacks=[checkpointer,lrReducer])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J8CfIJWr-0vp","colab_type":"code","colab":{}},"source":["def save_trained_model(model):\n","    model.save(\"model-4Conv-2Dense-10Epoch-wCallbacks.h5\")\n","\n","    \n","def load_trained_model(weights_path):\n","    model = create_model()\n","    model.load_weights(weights_path)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwUV0Zdx-0vv","colab_type":"code","outputId":"a66481ba-8e43-465b-d286-5350a45a4ea8","executionInfo":{"status":"ok","timestamp":1575474049564,"user_tz":-330,"elapsed":10182,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["modelv1 = create_model()\n","modelv1.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d (Conv2D)              (None, 398, 298, 64)      4864      \n","_________________________________________________________________\n","leaky_re_lu (LeakyReLU)      (None, 398, 298, 64)      0         \n","_________________________________________________________________\n","max_pooling2d (MaxPooling2D) (None, 199, 149, 64)      0         \n","_________________________________________________________________\n","dropout (Dropout)            (None, 199, 149, 64)      0         \n","_________________________________________________________________\n","conv2d_1 (Conv2D)            (None, 98, 73, 64)        102464    \n","_________________________________________________________________\n","leaky_re_lu_1 (LeakyReLU)    (None, 98, 73, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_1 (MaxPooling2 (None, 49, 36, 64)        0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 49, 36, 64)        0         \n","_________________________________________________________________\n","conv2d_2 (Conv2D)            (None, 24, 17, 64)        36928     \n","_________________________________________________________________\n","leaky_re_lu_2 (LeakyReLU)    (None, 24, 17, 64)        0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 24, 17, 64)        0         \n","_________________________________________________________________\n","conv2d_3 (Conv2D)            (None, 11, 8, 64)         36928     \n","_________________________________________________________________\n","leaky_re_lu_3 (LeakyReLU)    (None, 11, 8, 64)         0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 11, 8, 64)         0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 11, 8, 64)         256       \n","_________________________________________________________________\n","flatten (Flatten)            (None, 5632)              0         \n","_________________________________________________________________\n","dense (Dense)                (None, 64)                360512    \n","_________________________________________________________________\n","activation (Activation)      (None, 64)                0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 64)                0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 32)                2080      \n","_________________________________________________________________\n","leaky_re_lu_4 (LeakyReLU)    (None, 32)                0         \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 32)                0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 12)                396       \n","_________________________________________________________________\n","activation_1 (Activation)    (None, 12)                0         \n","=================================================================\n","Total params: 544,428\n","Trainable params: 544,300\n","Non-trainable params: 128\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OiZd9Pcw-0vy","colab_type":"code","outputId":"eda1ab07-c32e-402f-9bbe-b2d122b311d3","executionInfo":{"status":"error","timestamp":1575476095156,"user_tz":-330,"elapsed":2055763,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":921}},"source":["train_model(modelv1)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","91/92 [============================>.] - ETA: 3s - loss: 2.6315 - acc: 0.1054Epoch 1/10\n","14/92 [===>..........................] - ETA: 6:09 - loss: 2.4763 - acc: 0.1014\n","Epoch 00001: val_acc improved from -inf to 0.10135, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/4-3-weights2.hdf5\n","92/92 [==============================] - 357s 4s/step - loss: 2.6293 - acc: 0.1059 - val_loss: 2.4763 - val_acc: 0.1014\n","Epoch 2/10\n","91/92 [============================>.] - ETA: 2s - loss: 2.4883 - acc: 0.1150Epoch 1/10\n","14/92 [===>..........................] - ETA: 6:01 - loss: 2.4790 - acc: 0.1306\n","Epoch 00002: val_acc improved from 0.10135 to 0.13063, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/4-3-weights2.hdf5\n","92/92 [==============================] - 324s 4s/step - loss: 2.4874 - acc: 0.1155 - val_loss: 2.4790 - val_acc: 0.1306\n","Epoch 3/10\n","91/92 [============================>.] - ETA: 2s - loss: 2.4426 - acc: 0.1306Epoch 1/10\n","14/92 [===>..........................] - ETA: 6:08 - loss: 2.5421 - acc: 0.1486\n","Epoch 00003: val_acc improved from 0.13063 to 0.14865, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/4-3-weights2.hdf5\n","92/92 [==============================] - 326s 4s/step - loss: 2.4424 - acc: 0.1298 - val_loss: 2.5421 - val_acc: 0.1486\n","Epoch 4/10\n","91/92 [============================>.] - ETA: 2s - loss: 2.4315 - acc: 0.1478Epoch 1/10\n","14/92 [===>..........................] - ETA: 6:15 - loss: 2.4370 - acc: 0.1509\n","Epoch 00004: val_acc improved from 0.14865 to 0.15090, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/4-3-weights2.hdf5\n","92/92 [==============================] - 326s 4s/step - loss: 2.4302 - acc: 0.1486 - val_loss: 2.4370 - val_acc: 0.1509\n","Epoch 5/10\n","91/92 [============================>.] - ETA: 2s - loss: 2.4318 - acc: 0.1406Epoch 1/10\n","14/92 [===>..........................] - ETA: 6:08 - loss: 4.2596 - acc: 0.0901\n","Epoch 00005: val_acc did not improve from 0.15090\n","92/92 [==============================] - 324s 4s/step - loss: 2.4300 - acc: 0.1397 - val_loss: 4.2596 - val_acc: 0.0901\n","Epoch 6/10\n","91/92 [============================>.] - ETA: 2s - loss: 2.4057 - acc: 0.1423Epoch 1/10\n","14/92 [===>..........................] - ETA: 6:08 - loss: 2.4474 - acc: 0.1036\n","Epoch 00006: val_acc did not improve from 0.15090\n","92/92 [==============================] - 324s 4s/step - loss: 2.4058 - acc: 0.1425 - val_loss: 2.4474 - val_acc: 0.1036\n","Epoch 7/10\n","30/92 [========>.....................] - ETA: 2:07 - loss: 2.3597 - acc: 0.1665"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-60725bc7371c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-00b57b046645>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtensorboard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlrReducer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtarget_steps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m       \u001b[0mbatch_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36m_get_next_batch\u001b[0;34m(generator)\u001b[0m\n\u001b[1;32m    361\u001b[0m   \u001b[0;34m\"\"\"Retrieves the next batch of input data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 783\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    784\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"HpvSAroFovx_","colab_type":"code","outputId":"e40d5dbc-f35b-4e4d-cce2-41670afabf99","executionInfo":{"status":"ok","timestamp":1575537313372,"user_tz":-330,"elapsed":2708,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from tensorflow.keras.optimizers import Adadelta\n","def create_model2():\n","    model=Sequential()\n","    \n","    #layer1\n","    model.add(Conv2D(64,kernel_size=(3,3), strides=(2,2),input_shape=inputDims))\n","    model.add(BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(MaxPooling2D())\n","    \n","    #layer2\n","    model.add(Conv2D(64,kernel_size=(3,3), strides=(2,2),input_shape=inputDims))\n","    model.add(BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(MaxPooling2D())\n","    model.add(Dropout(0.2))\n","    \n","    #layer3\n","    model.add(Conv2D(64,kernel_size=(3,3), strides=(2,2),input_shape=inputDims))\n","    model.add(BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001))\n","    model.add(LeakyReLU(alpha=0.05))\n","    #model.add(MaxPooling2D())\n","    model.add(Dropout(0.2))\n","    \n","\n","    #layer4\n","    model.add(Conv2D(64,kernel_size=(3,3), strides=(2,2),input_shape=inputDims))\n","    model.add(BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001))\n","    model.add(LeakyReLU(alpha=0.05))\n","    model.add(MaxPooling2D())\n","    model.add(Dropout(0.2))\n","    \n","    #layer5\n","    model.add(Conv2D(64,kernel_size=(3,3), strides=(2,2),input_shape=inputDims))\n","    model.add(LeakyReLU(alpha=0.05))\n","    \n","    model.add(Flatten())\n","\n","    #layer6\n","    #affine layer + batch normalization...\n","    model.add(Dense(64))\n","    model.add(BatchNormalization(axis=-1,momentum=0.99,epsilon=0.001))\n","    model.add(Activation(\"relu\"))\n","\n","    #layer7\n","    #affine layer...\n","    model.add(Dense(12))\n","    model.add(Activation(\"softmax\"))\n","    \n","    return model\n","\n","\n","def train_model2(model):\n","    \n","    model.compile(loss=categorical_crossentropy, metrics=['accuracy'], optimizer='adam')\n","    \n","    lrReducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.001)\n","    \n","    chkpt_dir = \"/content/gdrive/My Drive/Colab Notebooks/chkpts\"\n","    checkpointer = ModelCheckpoint(monitor='val_acc',filepath=os.path.join(chkpt_dir,\"5Conv-2Aff-Adadelata-weights.hdf5\"), \n","                                   verbose=1, save_best_only=True)\n","    \n","    log_dir=\"logs\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","    tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n","    \n","    model.fit_generator(train,epochs=20,validation_data=val,callbacks=[checkpointer,lrReducer])\n","\n","\n","\n","modelv2 = create_model2()\n","modelv2.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_25 (Conv2D)           (None, 399, 299, 64)      1792      \n","_________________________________________________________________\n","batch_normalization_25 (Batc (None, 399, 299, 64)      256       \n","_________________________________________________________________\n","leaky_re_lu_25 (LeakyReLU)   (None, 399, 299, 64)      0         \n","_________________________________________________________________\n","max_pooling2d_15 (MaxPooling (None, 199, 149, 64)      0         \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 99, 74, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_26 (Batc (None, 99, 74, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_26 (LeakyReLU)   (None, 99, 74, 64)        0         \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 49, 37, 64)        0         \n","_________________________________________________________________\n","dropout_15 (Dropout)         (None, 49, 37, 64)        0         \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 24, 18, 64)        36928     \n","_________________________________________________________________\n","batch_normalization_27 (Batc (None, 24, 18, 64)        256       \n","_________________________________________________________________\n","leaky_re_lu_27 (LeakyReLU)   (None, 24, 18, 64)        0         \n","_________________________________________________________________\n","dropout_16 (Dropout)         (None, 24, 18, 64)        0         \n","_________________________________________________________________\n","conv2d_28 (Conv2D)           (None, 11, 8, 64)         36928     \n","_________________________________________________________________\n","batch_normalization_28 (Batc (None, 11, 8, 64)         256       \n","_________________________________________________________________\n","leaky_re_lu_28 (LeakyReLU)   (None, 11, 8, 64)         0         \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 5, 4, 64)          0         \n","_________________________________________________________________\n","dropout_17 (Dropout)         (None, 5, 4, 64)          0         \n","_________________________________________________________________\n","conv2d_29 (Conv2D)           (None, 2, 1, 64)          36928     \n","_________________________________________________________________\n","leaky_re_lu_29 (LeakyReLU)   (None, 2, 1, 64)          0         \n","_________________________________________________________________\n","flatten_5 (Flatten)          (None, 128)               0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","batch_normalization_29 (Batc (None, 64)                256       \n","_________________________________________________________________\n","activation_10 (Activation)   (None, 64)                0         \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 12)                780       \n","_________________________________________________________________\n","activation_11 (Activation)   (None, 12)                0         \n","=================================================================\n","Total params: 159,820\n","Trainable params: 159,180\n","Non-trainable params: 640\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fdbyKXW2sX00","colab_type":"code","outputId":"590f1a8d-dd4c-4bd5-a05e-6dfaf2ce9b58","executionInfo":{"status":"ok","timestamp":1575546033509,"user_tz":-330,"elapsed":8703336,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","train_model2(modelv2)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","91/92 [============================>.] - ETA: 4s - loss: 2.4168 - acc: 0.1762Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:10 - loss: 2.6500 - acc: 0.0833\n","Epoch 00001: val_acc improved from -inf to 0.08333, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 478s 5s/step - loss: 2.4152 - acc: 0.1763 - val_loss: 2.6500 - val_acc: 0.0833\n","Epoch 2/20\n","91/92 [============================>.] - ETA: 3s - loss: 2.1022 - acc: 0.2898Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:30 - loss: 2.6801 - acc: 0.1239\n","Epoch 00002: val_acc improved from 0.08333 to 0.12387, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 441s 5s/step - loss: 2.1011 - acc: 0.2907 - val_loss: 2.6801 - val_acc: 0.1239\n","Epoch 3/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.9920 - acc: 0.3250Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:20 - loss: 2.6736 - acc: 0.1126\n","Epoch 00003: val_acc did not improve from 0.12387\n","92/92 [==============================] - 432s 5s/step - loss: 1.9898 - acc: 0.3259 - val_loss: 2.6736 - val_acc: 0.1126\n","Epoch 4/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.8656 - acc: 0.3765Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:11 - loss: 2.8319 - acc: 0.1644\n","Epoch 00004: val_acc improved from 0.12387 to 0.16441, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 430s 5s/step - loss: 1.8649 - acc: 0.3762 - val_loss: 2.8319 - val_acc: 0.1644\n","Epoch 5/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.7942 - acc: 0.3803Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:17 - loss: 2.3792 - acc: 0.2297\n","Epoch 00005: val_acc improved from 0.16441 to 0.22973, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 431s 5s/step - loss: 1.7954 - acc: 0.3799 - val_loss: 2.3792 - val_acc: 0.2297\n","Epoch 6/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.7265 - acc: 0.4090Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:11 - loss: 2.2093 - acc: 0.2883\n","Epoch 00006: val_acc improved from 0.22973 to 0.28829, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 431s 5s/step - loss: 1.7277 - acc: 0.4096 - val_loss: 2.2093 - val_acc: 0.2883\n","Epoch 7/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.6855 - acc: 0.4190Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:07 - loss: 2.2504 - acc: 0.2185\n","Epoch 00007: val_acc did not improve from 0.28829\n","92/92 [==============================] - 430s 5s/step - loss: 1.6829 - acc: 0.4195 - val_loss: 2.2504 - val_acc: 0.2185\n","Epoch 8/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.6276 - acc: 0.4491Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:22 - loss: 1.9816 - acc: 0.3086\n","Epoch 00008: val_acc improved from 0.28829 to 0.30856, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 436s 5s/step - loss: 1.6291 - acc: 0.4489 - val_loss: 1.9816 - val_acc: 0.3086\n","Epoch 9/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.5712 - acc: 0.4587Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:27 - loss: 2.0295 - acc: 0.3153\n","Epoch 00009: val_acc improved from 0.30856 to 0.31532, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 435s 5s/step - loss: 1.5698 - acc: 0.4585 - val_loss: 2.0295 - val_acc: 0.3153\n","Epoch 10/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.5418 - acc: 0.4760Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:24 - loss: 1.7751 - acc: 0.4009\n","Epoch 00010: val_acc improved from 0.31532 to 0.40090, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/5Conv-2Aff-Adadelata-weights.hdf5\n","92/92 [==============================] - 437s 5s/step - loss: 1.5425 - acc: 0.4759 - val_loss: 1.7751 - val_acc: 0.4009\n","Epoch 11/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.4865 - acc: 0.4981Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:30 - loss: 1.8551 - acc: 0.3716\n","Epoch 00011: val_acc did not improve from 0.40090\n","92/92 [==============================] - 434s 5s/step - loss: 1.4875 - acc: 0.4978 - val_loss: 1.8551 - val_acc: 0.3716\n","Epoch 12/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.4688 - acc: 0.5019Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:19 - loss: 2.6242 - acc: 0.2207\n","Epoch 00012: val_acc did not improve from 0.40090\n","92/92 [==============================] - 432s 5s/step - loss: 1.4695 - acc: 0.5005 - val_loss: 2.6242 - val_acc: 0.2207\n","Epoch 13/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.4331 - acc: 0.5085Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:28 - loss: 1.8753 - acc: 0.3671\n","Epoch 00013: val_acc did not improve from 0.40090\n","92/92 [==============================] - 436s 5s/step - loss: 1.4322 - acc: 0.5087 - val_loss: 1.8753 - val_acc: 0.3671\n","Epoch 14/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.3857 - acc: 0.5178Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:15 - loss: 1.9203 - acc: 0.3288\n","Epoch 00014: val_acc did not improve from 0.40090\n","92/92 [==============================] - 431s 5s/step - loss: 1.3837 - acc: 0.5193 - val_loss: 1.9203 - val_acc: 0.3288\n","Epoch 15/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.3822 - acc: 0.5181Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:14 - loss: 2.0396 - acc: 0.3221\n","Epoch 00015: val_acc did not improve from 0.40090\n","92/92 [==============================] - 430s 5s/step - loss: 1.3799 - acc: 0.5190 - val_loss: 2.0396 - val_acc: 0.3221\n","Epoch 16/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.3432 - acc: 0.5333Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:16 - loss: 2.4343 - acc: 0.2815\n","Epoch 00016: val_acc did not improve from 0.40090\n","92/92 [==============================] - 431s 5s/step - loss: 1.3405 - acc: 0.5337 - val_loss: 2.4343 - val_acc: 0.2815\n","Epoch 17/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.3420 - acc: 0.5316Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:09 - loss: 1.9362 - acc: 0.3739\n","Epoch 00017: val_acc did not improve from 0.40090\n","92/92 [==============================] - 431s 5s/step - loss: 1.3454 - acc: 0.5278 - val_loss: 1.9362 - val_acc: 0.3739\n","Epoch 18/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.3236 - acc: 0.5413Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:14 - loss: 2.1357 - acc: 0.3739\n","Epoch 00018: val_acc did not improve from 0.40090\n","92/92 [==============================] - 431s 5s/step - loss: 1.3203 - acc: 0.5429 - val_loss: 2.1357 - val_acc: 0.3739\n","Epoch 19/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.2899 - acc: 0.5537Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:14 - loss: 1.9828 - acc: 0.3491\n","Epoch 00019: val_acc did not improve from 0.40090\n","92/92 [==============================] - 432s 5s/step - loss: 1.2921 - acc: 0.5531 - val_loss: 1.9828 - val_acc: 0.3491\n","Epoch 20/20\n","91/92 [============================>.] - ETA: 3s - loss: 1.3036 - acc: 0.5482Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:12 - loss: 2.0675 - acc: 0.3514\n","Epoch 00020: val_acc did not improve from 0.40090\n","92/92 [==============================] - 431s 5s/step - loss: 1.3028 - acc: 0.5494 - val_loss: 2.0675 - val_acc: 0.3514\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jRK-n1d2tB-O","colab_type":"code","outputId":"d656a1ef-720c-4850-8795-ebe7d14dfb49","executionInfo":{"status":"ok","timestamp":1575640199969,"user_tz":-330,"elapsed":7604,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["from tensorflow.keras import applications as app\n","from tensorflow.keras import Model\n","benchmarkModel = app.xception.Xception(weights='imagenet',include_top=False,input_shape=(800,600,3))\n","for layers in benchmarkModel.layers[:-5]:\n","    layers.trainable=False\n","\n","x = benchmarkModel.output\n","x = Dropout(0.5)(x)\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(128,activation='sigmoid')(x)\n","x = Dropout(0.5)(x)\n","pred = Dense(12,activation='softmax')(x)\n","model = Model(inputs=benchmarkModel.input, outputs=pred)\n","\n","model.summary()\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","lrReducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.001)\n","    \n","chkpt_dir = \"/content/gdrive/My Drive/Colab Notebooks/chkpts\"\n","checkpointer = ModelCheckpoint(monitor='val_acc',filepath=os.path.join(chkpt_dir,\"imagenet-last5-128affine-Adam-weights.hdf5\"), \n","                                   verbose=1, save_best_only=True)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"model_2\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, 800, 600, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 399, 299, 32) 864         input_3[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 399, 299, 32) 128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 399, 299, 32) 0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 397, 297, 64) 18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 397, 297, 64) 256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 397, 297, 64) 0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 397, 297, 128 8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 397, 297, 128 512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 397, 297, 128 0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 397, 297, 128 17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 397, 297, 128 512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_8 (Conv2D)               (None, 199, 149, 128 8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 199, 149, 128 0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_8 (BatchNor (None, 199, 149, 128 512         conv2d_8[0][0]                   \n","__________________________________________________________________________________________________\n","add_24 (Add)                    (None, 199, 149, 128 0           block2_pool[0][0]                \n","                                                                 batch_normalization_8[0][0]      \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 199, 149, 128 0           add_24[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 199, 149, 256 33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 199, 149, 256 1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 199, 149, 256 0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 199, 149, 256 67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 199, 149, 256 1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_9 (Conv2D)               (None, 100, 75, 256) 32768       add_24[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 100, 75, 256) 0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_9 (BatchNor (None, 100, 75, 256) 1024        conv2d_9[0][0]                   \n","__________________________________________________________________________________________________\n","add_25 (Add)                    (None, 100, 75, 256) 0           block3_pool[0][0]                \n","                                                                 batch_normalization_9[0][0]      \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 100, 75, 256) 0           add_25[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 100, 75, 728) 188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 100, 75, 728) 2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 100, 75, 728) 0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 100, 75, 728) 536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 100, 75, 728) 2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_10 (Conv2D)              (None, 50, 38, 728)  186368      add_25[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 50, 38, 728)  0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_10 (BatchNo (None, 50, 38, 728)  2912        conv2d_10[0][0]                  \n","__________________________________________________________________________________________________\n","add_26 (Add)                    (None, 50, 38, 728)  0           block4_pool[0][0]                \n","                                                                 batch_normalization_10[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 50, 38, 728)  0           add_26[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 50, 38, 728)  536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 50, 38, 728)  2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 50, 38, 728)  0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 50, 38, 728)  536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 50, 38, 728)  2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 50, 38, 728)  0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 50, 38, 728)  536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 50, 38, 728)  2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_27 (Add)                    (None, 50, 38, 728)  0           block5_sepconv3_bn[0][0]         \n","                                                                 add_26[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 50, 38, 728)  0           add_27[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 50, 38, 728)  536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 50, 38, 728)  2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 50, 38, 728)  0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 50, 38, 728)  536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 50, 38, 728)  2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 50, 38, 728)  0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 50, 38, 728)  536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 50, 38, 728)  2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_28 (Add)                    (None, 50, 38, 728)  0           block6_sepconv3_bn[0][0]         \n","                                                                 add_27[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 50, 38, 728)  0           add_28[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 50, 38, 728)  536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 50, 38, 728)  2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 50, 38, 728)  0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 50, 38, 728)  536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 50, 38, 728)  2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 50, 38, 728)  0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 50, 38, 728)  536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 50, 38, 728)  2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_29 (Add)                    (None, 50, 38, 728)  0           block7_sepconv3_bn[0][0]         \n","                                                                 add_28[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 50, 38, 728)  0           add_29[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 50, 38, 728)  536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 50, 38, 728)  2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 50, 38, 728)  0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 50, 38, 728)  536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 50, 38, 728)  2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 50, 38, 728)  0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 50, 38, 728)  536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 50, 38, 728)  2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_30 (Add)                    (None, 50, 38, 728)  0           block8_sepconv3_bn[0][0]         \n","                                                                 add_29[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 50, 38, 728)  0           add_30[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 50, 38, 728)  536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 50, 38, 728)  2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 50, 38, 728)  0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 50, 38, 728)  536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 50, 38, 728)  2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 50, 38, 728)  0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 50, 38, 728)  536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 50, 38, 728)  2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_31 (Add)                    (None, 50, 38, 728)  0           block9_sepconv3_bn[0][0]         \n","                                                                 add_30[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 50, 38, 728)  0           add_31[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 50, 38, 728)  536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 50, 38, 728)  2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 50, 38, 728)  0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 50, 38, 728)  536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 50, 38, 728)  2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 50, 38, 728)  0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 50, 38, 728)  536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 50, 38, 728)  2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_32 (Add)                    (None, 50, 38, 728)  0           block10_sepconv3_bn[0][0]        \n","                                                                 add_31[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 50, 38, 728)  0           add_32[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 50, 38, 728)  536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 50, 38, 728)  2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 50, 38, 728)  0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 50, 38, 728)  536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 50, 38, 728)  2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 50, 38, 728)  0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 50, 38, 728)  536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 50, 38, 728)  2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_33 (Add)                    (None, 50, 38, 728)  0           block11_sepconv3_bn[0][0]        \n","                                                                 add_32[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 50, 38, 728)  0           add_33[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 50, 38, 728)  536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 50, 38, 728)  2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 50, 38, 728)  0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 50, 38, 728)  536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 50, 38, 728)  2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 50, 38, 728)  0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 50, 38, 728)  536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 50, 38, 728)  2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_34 (Add)                    (None, 50, 38, 728)  0           block12_sepconv3_bn[0][0]        \n","                                                                 add_33[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 50, 38, 728)  0           add_34[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 50, 38, 728)  536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 50, 38, 728)  2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 50, 38, 728)  0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 50, 38, 1024) 752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 50, 38, 1024) 4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_11 (Conv2D)              (None, 25, 19, 1024) 745472      add_34[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 25, 19, 1024) 0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_11 (BatchNo (None, 25, 19, 1024) 4096        conv2d_11[0][0]                  \n","__________________________________________________________________________________________________\n","add_35 (Add)                    (None, 25, 19, 1024) 0           block13_pool[0][0]               \n","                                                                 batch_normalization_11[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 25, 19, 1536) 1582080     add_35[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 25, 19, 1536) 6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 25, 19, 1536) 0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 25, 19, 2048) 3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 25, 19, 2048) 8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 25, 19, 2048) 0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","dropout_4 (Dropout)             (None, 25, 19, 2048) 0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","global_average_pooling2d_2 (Glo (None, 2048)         0           dropout_4[0][0]                  \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 128)          262272      global_average_pooling2d_2[0][0] \n","__________________________________________________________________________________________________\n","dropout_5 (Dropout)             (None, 128)          0           dense_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_5 (Dense)                 (None, 12)           1548        dropout_5[0][0]                  \n","==================================================================================================\n","Total params: 21,125,300\n","Trainable params: 3,430,540\n","Non-trainable params: 17,694,760\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N8R6nXOZmecG","colab_type":"code","outputId":"70025073-548b-46ba-d01b-08d00a9acaa9","executionInfo":{"status":"ok","timestamp":1575652566425,"user_tz":-330,"elapsed":12100749,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["model.fit_generator(train,epochs=20,validation_data=val,callbacks=[checkpointer,lrReducer])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 1/20\n","91/92 [============================>.] - ETA: 15s - loss: 1.6577 - acc: 0.4449Epoch 1/20\n","14/92 [===>..........................] - ETA: 22:25 - loss: 2.3174 - acc: 0.2635\n","Epoch 00001: val_acc improved from -inf to 0.26351, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last5-128affine-Adam-weights.hdf5\n","92/92 [==============================] - 1738s 19s/step - loss: 1.6522 - acc: 0.4469 - val_loss: 2.3174 - val_acc: 0.2635\n","Epoch 2/20\n","91/92 [============================>.] - ETA: 4s - loss: 1.0053 - acc: 0.6611Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:58 - loss: 2.2167 - acc: 0.3491\n","Epoch 00002: val_acc improved from 0.26351 to 0.34910, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last5-128affine-Adam-weights.hdf5\n","92/92 [==============================] - 544s 6s/step - loss: 1.0056 - acc: 0.6607 - val_loss: 2.2167 - val_acc: 0.3491\n","Epoch 3/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.8625 - acc: 0.7033Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:50 - loss: 2.0424 - acc: 0.4032\n","Epoch 00003: val_acc improved from 0.34910 to 0.40315, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last5-128affine-Adam-weights.hdf5\n","92/92 [==============================] - 543s 6s/step - loss: 0.8627 - acc: 0.7031 - val_loss: 2.0424 - val_acc: 0.4032\n","Epoch 4/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.7710 - acc: 0.7409Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:53 - loss: 2.0974 - acc: 0.3761\n","Epoch 00004: val_acc did not improve from 0.40315\n","92/92 [==============================] - 541s 6s/step - loss: 0.7699 - acc: 0.7414 - val_loss: 2.0974 - val_acc: 0.3761\n","Epoch 5/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.7013 - acc: 0.7651Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:55 - loss: 1.9891 - acc: 0.4324\n","Epoch 00005: val_acc improved from 0.40315 to 0.43243, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last5-128affine-Adam-weights.hdf5\n","92/92 [==============================] - 547s 6s/step - loss: 0.7010 - acc: 0.7643 - val_loss: 1.9891 - val_acc: 0.4324\n","Epoch 6/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.6348 - acc: 0.7858Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:50 - loss: 2.6805 - acc: 0.2680\n","Epoch 00006: val_acc did not improve from 0.43243\n","92/92 [==============================] - 547s 6s/step - loss: 0.6339 - acc: 0.7858 - val_loss: 2.6805 - val_acc: 0.2680\n","Epoch 7/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.5775 - acc: 0.8024Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:54 - loss: 1.8099 - acc: 0.4887\n","Epoch 00007: val_acc improved from 0.43243 to 0.48874, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last5-128affine-Adam-weights.hdf5\n","92/92 [==============================] - 547s 6s/step - loss: 0.5760 - acc: 0.8029 - val_loss: 1.8099 - val_acc: 0.4887\n","Epoch 8/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.5335 - acc: 0.8138Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:55 - loss: 2.3309 - acc: 0.3378\n","Epoch 00008: val_acc did not improve from 0.48874\n","92/92 [==============================] - 543s 6s/step - loss: 0.5336 - acc: 0.8131 - val_loss: 2.3309 - val_acc: 0.3378\n","Epoch 9/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.4963 - acc: 0.8321Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:59 - loss: 2.1416 - acc: 0.4730\n","Epoch 00009: val_acc did not improve from 0.48874\n","92/92 [==============================] - 545s 6s/step - loss: 0.4938 - acc: 0.8336 - val_loss: 2.1416 - val_acc: 0.4730\n","Epoch 10/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.4606 - acc: 0.8518Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:55 - loss: 2.4058 - acc: 0.3626\n","Epoch 00010: val_acc did not improve from 0.48874\n","92/92 [==============================] - 546s 6s/step - loss: 0.4615 - acc: 0.8507 - val_loss: 2.4058 - val_acc: 0.3626\n","Epoch 11/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.4333 - acc: 0.8542Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:56 - loss: 2.9834 - acc: 0.2815\n","Epoch 00011: val_acc did not improve from 0.48874\n","92/92 [==============================] - 550s 6s/step - loss: 0.4319 - acc: 0.8541 - val_loss: 2.9834 - val_acc: 0.2815\n","Epoch 12/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.3820 - acc: 0.8750Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:47 - loss: 2.7607 - acc: 0.2905\n","Epoch 00012: val_acc did not improve from 0.48874\n","92/92 [==============================] - 541s 6s/step - loss: 0.3821 - acc: 0.8750 - val_loss: 2.7607 - val_acc: 0.2905\n","Epoch 13/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.3749 - acc: 0.8715Epoch 1/20\n","14/92 [===>..........................] - ETA: 9:01 - loss: 2.3687 - acc: 0.3581\n","Epoch 00013: val_acc did not improve from 0.48874\n","92/92 [==============================] - 556s 6s/step - loss: 0.3759 - acc: 0.8719 - val_loss: 2.3687 - val_acc: 0.3581\n","Epoch 14/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.3385 - acc: 0.8884Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:52 - loss: 2.4880 - acc: 0.3896\n","Epoch 00014: val_acc did not improve from 0.48874\n","92/92 [==============================] - 553s 6s/step - loss: 0.3397 - acc: 0.8879 - val_loss: 2.4880 - val_acc: 0.3896\n","Epoch 15/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.3110 - acc: 0.8940Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:47 - loss: 2.3191 - acc: 0.3716\n","Epoch 00015: val_acc did not improve from 0.48874\n","92/92 [==============================] - 553s 6s/step - loss: 0.3101 - acc: 0.8948 - val_loss: 2.3191 - val_acc: 0.3716\n","Epoch 16/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.3013 - acc: 0.9009Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:57 - loss: 2.4884 - acc: 0.3739\n","Epoch 00016: val_acc did not improve from 0.48874\n","92/92 [==============================] - 554s 6s/step - loss: 0.3000 - acc: 0.9016 - val_loss: 2.4884 - val_acc: 0.3739\n","Epoch 17/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.2516 - acc: 0.9161Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:55 - loss: 3.0051 - acc: 0.2860\n","Epoch 00017: val_acc did not improve from 0.48874\n","92/92 [==============================] - 550s 6s/step - loss: 0.2517 - acc: 0.9163 - val_loss: 3.0051 - val_acc: 0.2860\n","Epoch 18/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.2510 - acc: 0.9147Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:52 - loss: 3.1049 - acc: 0.3131\n","Epoch 00018: val_acc did not improve from 0.48874\n","92/92 [==============================] - 552s 6s/step - loss: 0.2520 - acc: 0.9146 - val_loss: 3.1049 - val_acc: 0.3131\n","Epoch 19/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.2496 - acc: 0.9150Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:10 - loss: 3.1146 - acc: 0.3176\n","Epoch 00019: val_acc did not improve from 0.48874\n","92/92 [==============================] - 542s 6s/step - loss: 0.2495 - acc: 0.9153 - val_loss: 3.1146 - val_acc: 0.3176\n","Epoch 20/20\n","91/92 [============================>.] - ETA: 4s - loss: 0.2197 - acc: 0.9261Epoch 1/20\n","14/92 [===>..........................] - ETA: 8:21 - loss: 2.5787 - acc: 0.3806\n","Epoch 00020: val_acc did not improve from 0.48874\n","92/92 [==============================] - 507s 6s/step - loss: 0.2206 - acc: 0.9255 - val_loss: 2.5787 - val_acc: 0.3806\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fe383443278>"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"0ZW-ZdNxGYzI","colab_type":"text"},"source":["ok...so the validation accuracy is plumetting meaning the model is overfitting...\n","so we need to add more examples and drop features....\n","the first improvement would be to add more features through data augmentation. this step would hopefully create more images for the model to train from\n","the second improvement would be to to drop features which are not contributing to the classification.\n","this could be done by cropping out the middle area"]},{"cell_type":"code","metadata":{"id":"yM4EfSp4GtzP","colab_type":"code","outputId":"6f8931f6-2ac6-4618-c03a-bec0a37f55ce","executionInfo":{"status":"error","timestamp":1575902899355,"user_tz":-330,"elapsed":160720,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}},"colab":{"base_uri":"https://localhost:8080/","height":551}},"source":["!pip install Augmentor\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting Augmentor\n","  Downloading https://files.pythonhosted.org/packages/c9/d2/05184ea0e0c12f85d68da7b96fd6c05f294862143758314fcb2a9951d338/Augmentor-0.2.6-py2.py3-none-any.whl\n","Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.28.1)\n","Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.3.0)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.17.4)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=4.0.0->Augmentor) (0.46)\n","Installing collected packages: Augmentor\n","Successfully installed Augmentor-0.2.6\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b31d0917ee94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install Augmentor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAugmentor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAugmentor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_directory, output_directory, save_format)\u001b[0m\n\u001b[1;32m     88\u001b[0m                            \u001b[0moutput_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_directory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                            \u001b[0mground_truth_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                            ground_truth_output_directory=output_directory)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugmentor_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m_populate\u001b[0;34m(self, source_directory, output_directory, ground_truth_directory, ground_truth_output_directory)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs_output_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_output_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_populate_image_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Augmentor/Pipeline.py\u001b[0m in \u001b[0;36m_check_images\u001b[0;34m(self, abs_output_directory)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maugmentor_image\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maugmentor_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maugmentor_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_image\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct_dimensions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistinct_formats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2537\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2539\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2541\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"7Y0H_hJozpsT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"outputId":"6aa22cd4-c6a9-4095-bd60-cbc2b771791d","executionInfo":{"status":"ok","timestamp":1575964941698,"user_tz":-330,"elapsed":3214,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["#checking a way to find the number of files in a folder...\n","AUG_TRAIN=\"/content/gdrive/My Drive/Colab Notebooks/Augmented Train\"\n","folder=\"Checked\"\n","\n","path, dirs, files = next(os.walk(os.path.join(TRAIN_DIR,folder)))\n","file_count = len(files)\n","print(file_count)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["258\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KiP5dOnCS1qz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":594},"outputId":"6d63fe50-7709-42ea-ac8f-aff1d9c2845d","executionInfo":{"status":"ok","timestamp":1575967812175,"user_tz":-330,"elapsed":1278052,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["!pip install Augmentor\n","import Augmentor\n","\n","#define a few important variables...\n","AUG_TRAIN = \"/content/gdrive/My Drive/Colab Notebooks/Augmented Train\"\n","augHeight = 600//2\n","augWidth = 800//2\n","augInc = 3\n","\n","#remove previous aug train dirs...\n","for root, dirs, files in os.walk(AUG_TRAIN, topdown=False):\n","    for name in files:\n","        os.remove(os.path.join(root, name))\n","    for name in dirs:\n","        os.rmdir(os.path.join(root, name))\n","\n","\n","\n","#re-make the target directories...\n","for folder in os.listdir(TRAIN_DIR):\n","    os.mkdir(os.path.join(AUG_TRAIN,folder))\n","\n","\n","#for every folder in training directory,\n","#mirror it with high probability\n","#zoom in a little bit at 50% probability\n","#rotate the image by maximum 10 degress CW or CCW at 20% probability\n","#finally crop the images to \"augSize\" as specified to reduce the features/pixel count...\n","#create augInc times the number of images\n","#i.e, if we have 300 imgs and augInc is set to 2, our dataset will double.\n","\n","for folder in os.listdir(AUG_TRAIN):\n","    p = Augmentor.Pipeline(source_directory=os.path.join(TRAIN_DIR,folder),output_directory=os.path.join(AUG_TRAIN,folder))\n","    p.flip_left_right(0.3)\n","    p.zoom(probability=0.3, min_factor=1.0, max_factor=1.4)\n","    p.rotate(0.2,10,10)\n","    p.crop_by_size(1,augHeight,augWidth)\n","    path, dirs, files = next(os.walk(os.path.join(TRAIN_DIR,folder)))\n","    p.sample(len(files)*augInc)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: Augmentor in /usr/local/lib/python3.6/dist-packages (0.2.6)\n","Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.28.1)\n","Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (1.17.4)\n","Requirement already satisfied: Pillow>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (4.3.0)\n","Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.6/dist-packages (from Augmentor) (0.16.0)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow>=4.0.0->Augmentor) (0.46)\n"],"name":"stdout"},{"output_type":"stream","text":["\rExecuting Pipeline:   0%|          | 0/774 [00:00<?, ? Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 258 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/polka dots."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA651E9550>: 100%|██████████| 774/774 [00:21<00:00, 36.00 Samples/s]\n","Executing Pipeline:   0%|          | 0/765 [00:00<?, ? Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 255 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/Patterned."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA5254D048>: 100%|██████████| 765/765 [00:13<00:00, 56.52 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA651E90B8>:   0%|          | 1/789 [00:00<01:56,  6.77 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 263 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/floral."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA525657F0>: 100%|██████████| 789/789 [00:21<00:00, 35.88 Samples/s]\n","Executing Pipeline:   0%|          | 0/792 [00:00<?, ? Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 264 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/graphic."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA651CB320>: 100%|██████████| 792/792 [00:21<00:00, 36.32 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA651E9A20>:   0%|          | 2/774 [00:00<01:14, 10.39 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 258 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/Checked."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA52554F60>: 100%|██████████| 774/774 [00:13<00:00, 57.05 Samples/s]\n","Executing Pipeline:   0%|          | 0/216 [00:00<?, ? Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 72 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/Colourblock."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA65103080>: 100%|██████████| 216/216 [00:14<00:00, 14.42 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA52554828>:   0%|          | 3/780 [00:00<01:42,  7.57 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 260 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/solid."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA524DE6D8>: 100%|██████████| 780/780 [00:20<00:00, 37.50 Samples/s]\n","Executing Pipeline:   0%|          | 0/774 [00:00<?, ? Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 258 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/Melange."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCAC2E85D30>: 100%|██████████| 774/774 [00:13<00:00, 55.87 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA6518DDD8>:   1%|          | 7/789 [00:00<02:02,  6.39 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 263 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/Printed."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA56AC9320>: 100%|██████████| 789/789 [00:13<00:00, 57.51 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64FD3BE0>:   0%|          | 0/768 [00:00<?, ? Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 256 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/abstract."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64FB3470>: 100%|██████████| 768/768 [00:21<00:00, 35.36 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA56AC9C88>:   0%|          | 3/771 [00:00<01:23,  9.16 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 257 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/striped."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64FD3CF8>: 100%|██████████| 771/771 [00:20<00:00, 37.57 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA56ABB828>:   0%|          | 1/789 [00:00<02:09,  6.06 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 263 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Train/typography."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA52519F98>: 100%|██████████| 789/789 [00:22<00:00, 35.67 Samples/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"WW-lUn9I151j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":258},"outputId":"a35cc2d6-8150-4d08-946a-2885640110bf","executionInfo":{"status":"ok","timestamp":1575968613848,"user_tz":-330,"elapsed":1412,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["sum=0\n","for folder in os.listdir(AUG_TRAIN):\n","    path, dirs, files = next(os.walk(os.path.join(AUG_TRAIN,folder)))\n","    file_count = len(files)\n","    print(file_count)\n","    sum += file_count\n","print(sum)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["796\n","765\n","789\n","792\n","774\n","216\n","780\n","774\n","789\n","768\n","771\n","789\n","8803\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y-iRLHvdDpMu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":483},"outputId":"8292ae3e-12f6-4f51-c113-55f226c13566","executionInfo":{"status":"ok","timestamp":1575969270888,"user_tz":-330,"elapsed":179946,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["#os.mkdir(\"/content/gdrive/My Drive/Colab Notebooks/Augmented Validation\")\n","AUG_VAL = \"/content/gdrive/My Drive/Colab Notebooks/Augmented Validation\"\n","\n","#remove previous aug val dirs...\n","for root, dirs, files in os.walk(AUG_VAL, topdown=False):\n","    for name in files:\n","        os.remove(os.path.join(root, name))\n","    for name in dirs:\n","        os.rmdir(os.path.join(root, name))\n","\n","\n","\n","#re-make the target directories...\n","for folder in os.listdir(VAL_DIR):\n","    os.mkdir(os.path.join(AUG_VAL,folder))\n","\n","\n","for folder in os.listdir(AUG_VAL):\n","    p = Augmentor.Pipeline(source_directory=os.path.join(VAL_DIR,folder),output_directory=os.path.join(AUG_VAL,folder))\n","    p.crop_by_size(1,augHeight,augWidth)\n","    path, dirs, files = next(os.walk(os.path.join(VAL_DIR,folder)))\n","    p.sample(len(files))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F66940>:  24%|██▍       | 9/37 [00:00<00:00, 39.71 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/abstract."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F66518>: 100%|██████████| 37/37 [00:00<00:00, 74.33 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F48A90>:  30%|██▉       | 11/37 [00:00<00:00, 27.77 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/Checked."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5BB00>: 100%|██████████| 37/37 [00:00<00:00, 85.80 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F486A0>:  30%|██▉       | 11/37 [00:00<00:00, 29.38 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/Colourblock."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64FD32E8>: 100%|██████████| 37/37 [00:00<00:00, 57.10 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5F278>:  19%|█▉        | 7/37 [00:00<00:03,  8.10 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/floral."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5BD30>: 100%|██████████| 37/37 [00:00<00:00, 64.66 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F53DA0>:  24%|██▍       | 9/37 [00:00<00:01, 17.12 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/graphic."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5FE80>: 100%|██████████| 37/37 [00:00<00:00, 76.56 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5B518>:  30%|██▉       | 11/37 [00:00<00:00, 29.69 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/Melange."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F66128>: 100%|██████████| 37/37 [00:00<00:00, 82.59 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F53198>:  24%|██▍       | 9/37 [00:00<00:03,  7.78 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/polka dots."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F48160>: 100%|██████████| 37/37 [00:00<00:00, 75.48 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F53908>:  30%|██▉       | 11/37 [00:00<00:00, 36.44 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/Patterned."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F661D0>: 100%|██████████| 37/37 [00:00<00:00, 83.45 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5BC50>:  38%|███▊      | 14/37 [00:00<00:00, 47.58 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/Printed."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F53400>: 100%|██████████| 37/37 [00:00<00:00, 88.81 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F5B9B0>:  24%|██▍       | 9/37 [00:00<00:00, 38.50 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/solid."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F66898>: 100%|██████████| 37/37 [00:00<00:00, 79.10 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F48160>:  19%|█▉        | 7/37 [00:00<00:04,  7.43 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/striped."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F53940>: 100%|██████████| 37/37 [00:00<00:00, 72.39 Samples/s]\n","Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F3FEF0>:  22%|██▏       | 8/37 [00:00<00:01, 19.52 Samples/s]"],"name":"stderr"},{"output_type":"stream","text":["Initialised with 37 image(s) found.\n","Output directory set to /content/gdrive/My Drive/Colab Notebooks/Augmented Validation/typography."],"name":"stdout"},{"output_type":"stream","text":["Processing <PIL.Image.Image image mode=RGB size=300x400 at 0x7FCA64F485C0>: 100%|██████████| 37/37 [00:00<00:00, 69.72 Samples/s]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"Pd0OqV2ICtKq","colab_type":"code","colab":{}},"source":["def feeder(batch,targetSize):\n","    \n","    #take the image,flip it, scale brightness between 0.8 to 1.2 and finally rescale all images with range...\n","    #find the rescale value as per the ndarray dtype generated...\n","    \n","    #perform basic augmentation to increase the DL model's inputs...\n","    \n","    trainAugmenter = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8, 1.2],height_shift_range=0.1,width_shift_range=0.1,zoom_range=0.2,rescale=1./255)\n","    testAugmenter = ImageDataGenerator(horizontal_flip=True,brightness_range=[0.8, 1.2],height_shift_range=0.1,width_shift_range=0.1,zoom_range=0.2,rescale=1./255)\n","        \n","    \n","    #augmentation done...moving to create a flow from the directory for both train and test data...\n","    \n","    trainGen = trainAugmenter.flow_from_directory(AUG_TRAIN,shuffle=True,target_size=targetSize,\n","                                                  batch_size=batch,class_mode='categorical')\n","    \n","    testGen = testAugmenter.flow_from_directory(AUG_VAL,shuffle=True,target_size=targetSize,\n","                                               batch_size=batch,class_mode='categorical')\n","    \n","    \n","    #return a dictionary with both train and test generator objects...\n","    \n","    return {\"train\":trainGen,\n","            \"val\":testGen }"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iudsEM6fDk9z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"9c70aed0-66f5-42e6-cb1f-36debc84c566","executionInfo":{"status":"ok","timestamp":1575969400461,"user_tz":-330,"elapsed":3377,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["imageWidth  = 600//2\n","imageHeight = 800//2\n","imageChannel = 3\n","batch=32\n","\n","##generating a flow with given params...\n","data = feeder(batch,(imageHeight,imageWidth))\n","\n","\n","train = data[\"train\"]\n","X_train, Y_train=train.next()\n","val = data[\"val\"]\n","X_val, Y_val=val.next()\n"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Found 8781 images belonging to 12 classes.\n","Found 444 images belonging to 12 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Xm9CNB5IGJiS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"99e98541-3317-4a71-9e88-39ed40b0eb3d","executionInfo":{"status":"ok","timestamp":1575977133628,"user_tz":-330,"elapsed":8506,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["from tensorflow.keras import applications as app\n","from tensorflow.keras import Model\n","benchmarkModel = app.xception.Xception(weights='imagenet',include_top=False,input_shape=(400,300,3))\n","for layers in benchmarkModel.layers[:-4]:\n","    layers.trainable=False\n","\n","x = benchmarkModel.output\n","x = Dropout(0.5)(x)\n","x = GlobalAveragePooling2D()(x)\n","x = Dense(64,activation='sigmoid')(x)\n","x = Dropout(0.5)(x)\n","pred = Dense(12,activation='softmax')(x)\n","model = Model(inputs=benchmarkModel.input, outputs=pred)\n","\n","model.summary()\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","lrReducer = ReduceLROnPlateau(monitor='val_acc', factor=0.2, patience=3, min_lr=0.001)\n","    \n","chkpt_dir = \"/content/gdrive/My Drive/Colab Notebooks/chkpts\"\n","checkpointer = ModelCheckpoint(monitor='val_acc',filepath=os.path.join(chkpt_dir,\"imagenet-last4-64affine-Adam-wAugmentation-weights.hdf5\"), \n","                                   verbose=1, save_best_only=True)\n","\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Model: \"model_3\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_4 (InputLayer)            [(None, 400, 300, 3) 0                                            \n","__________________________________________________________________________________________________\n","block1_conv1 (Conv2D)           (None, 199, 149, 32) 864         input_4[0][0]                    \n","__________________________________________________________________________________________________\n","block1_conv1_bn (BatchNormaliza (None, 199, 149, 32) 128         block1_conv1[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv1_act (Activation)   (None, 199, 149, 32) 0           block1_conv1_bn[0][0]            \n","__________________________________________________________________________________________________\n","block1_conv2 (Conv2D)           (None, 197, 147, 64) 18432       block1_conv1_act[0][0]           \n","__________________________________________________________________________________________________\n","block1_conv2_bn (BatchNormaliza (None, 197, 147, 64) 256         block1_conv2[0][0]               \n","__________________________________________________________________________________________________\n","block1_conv2_act (Activation)   (None, 197, 147, 64) 0           block1_conv2_bn[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv1 (SeparableConv2 (None, 197, 147, 128 8768        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_sepconv1_bn (BatchNormal (None, 197, 147, 128 512         block2_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block2_sepconv2_act (Activation (None, 197, 147, 128 0           block2_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block2_sepconv2 (SeparableConv2 (None, 197, 147, 128 17536       block2_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block2_sepconv2_bn (BatchNormal (None, 197, 147, 128 512         block2_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_12 (Conv2D)              (None, 99, 74, 128)  8192        block1_conv2_act[0][0]           \n","__________________________________________________________________________________________________\n","block2_pool (MaxPooling2D)      (None, 99, 74, 128)  0           block2_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_12 (BatchNo (None, 99, 74, 128)  512         conv2d_12[0][0]                  \n","__________________________________________________________________________________________________\n","add_36 (Add)                    (None, 99, 74, 128)  0           block2_pool[0][0]                \n","                                                                 batch_normalization_12[0][0]     \n","__________________________________________________________________________________________________\n","block3_sepconv1_act (Activation (None, 99, 74, 128)  0           add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_sepconv1 (SeparableConv2 (None, 99, 74, 256)  33920       block3_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv1_bn (BatchNormal (None, 99, 74, 256)  1024        block3_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block3_sepconv2_act (Activation (None, 99, 74, 256)  0           block3_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block3_sepconv2 (SeparableConv2 (None, 99, 74, 256)  67840       block3_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block3_sepconv2_bn (BatchNormal (None, 99, 74, 256)  1024        block3_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_13 (Conv2D)              (None, 50, 37, 256)  32768       add_36[0][0]                     \n","__________________________________________________________________________________________________\n","block3_pool (MaxPooling2D)      (None, 50, 37, 256)  0           block3_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_13 (BatchNo (None, 50, 37, 256)  1024        conv2d_13[0][0]                  \n","__________________________________________________________________________________________________\n","add_37 (Add)                    (None, 50, 37, 256)  0           block3_pool[0][0]                \n","                                                                 batch_normalization_13[0][0]     \n","__________________________________________________________________________________________________\n","block4_sepconv1_act (Activation (None, 50, 37, 256)  0           add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_sepconv1 (SeparableConv2 (None, 50, 37, 728)  188672      block4_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv1_bn (BatchNormal (None, 50, 37, 728)  2912        block4_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block4_sepconv2_act (Activation (None, 50, 37, 728)  0           block4_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block4_sepconv2 (SeparableConv2 (None, 50, 37, 728)  536536      block4_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block4_sepconv2_bn (BatchNormal (None, 50, 37, 728)  2912        block4_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","conv2d_14 (Conv2D)              (None, 25, 19, 728)  186368      add_37[0][0]                     \n","__________________________________________________________________________________________________\n","block4_pool (MaxPooling2D)      (None, 25, 19, 728)  0           block4_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","batch_normalization_14 (BatchNo (None, 25, 19, 728)  2912        conv2d_14[0][0]                  \n","__________________________________________________________________________________________________\n","add_38 (Add)                    (None, 25, 19, 728)  0           block4_pool[0][0]                \n","                                                                 batch_normalization_14[0][0]     \n","__________________________________________________________________________________________________\n","block5_sepconv1_act (Activation (None, 25, 19, 728)  0           add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block5_sepconv1 (SeparableConv2 (None, 25, 19, 728)  536536      block5_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv1_bn (BatchNormal (None, 25, 19, 728)  2912        block5_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv2_act (Activation (None, 25, 19, 728)  0           block5_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv2 (SeparableConv2 (None, 25, 19, 728)  536536      block5_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv2_bn (BatchNormal (None, 25, 19, 728)  2912        block5_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block5_sepconv3_act (Activation (None, 25, 19, 728)  0           block5_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block5_sepconv3 (SeparableConv2 (None, 25, 19, 728)  536536      block5_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block5_sepconv3_bn (BatchNormal (None, 25, 19, 728)  2912        block5_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_39 (Add)                    (None, 25, 19, 728)  0           block5_sepconv3_bn[0][0]         \n","                                                                 add_38[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1_act (Activation (None, 25, 19, 728)  0           add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block6_sepconv1 (SeparableConv2 (None, 25, 19, 728)  536536      block6_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv1_bn (BatchNormal (None, 25, 19, 728)  2912        block6_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv2_act (Activation (None, 25, 19, 728)  0           block6_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv2 (SeparableConv2 (None, 25, 19, 728)  536536      block6_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv2_bn (BatchNormal (None, 25, 19, 728)  2912        block6_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block6_sepconv3_act (Activation (None, 25, 19, 728)  0           block6_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block6_sepconv3 (SeparableConv2 (None, 25, 19, 728)  536536      block6_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block6_sepconv3_bn (BatchNormal (None, 25, 19, 728)  2912        block6_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_40 (Add)                    (None, 25, 19, 728)  0           block6_sepconv3_bn[0][0]         \n","                                                                 add_39[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1_act (Activation (None, 25, 19, 728)  0           add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block7_sepconv1 (SeparableConv2 (None, 25, 19, 728)  536536      block7_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv1_bn (BatchNormal (None, 25, 19, 728)  2912        block7_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv2_act (Activation (None, 25, 19, 728)  0           block7_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv2 (SeparableConv2 (None, 25, 19, 728)  536536      block7_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv2_bn (BatchNormal (None, 25, 19, 728)  2912        block7_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block7_sepconv3_act (Activation (None, 25, 19, 728)  0           block7_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block7_sepconv3 (SeparableConv2 (None, 25, 19, 728)  536536      block7_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block7_sepconv3_bn (BatchNormal (None, 25, 19, 728)  2912        block7_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_41 (Add)                    (None, 25, 19, 728)  0           block7_sepconv3_bn[0][0]         \n","                                                                 add_40[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1_act (Activation (None, 25, 19, 728)  0           add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block8_sepconv1 (SeparableConv2 (None, 25, 19, 728)  536536      block8_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv1_bn (BatchNormal (None, 25, 19, 728)  2912        block8_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv2_act (Activation (None, 25, 19, 728)  0           block8_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv2 (SeparableConv2 (None, 25, 19, 728)  536536      block8_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv2_bn (BatchNormal (None, 25, 19, 728)  2912        block8_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block8_sepconv3_act (Activation (None, 25, 19, 728)  0           block8_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block8_sepconv3 (SeparableConv2 (None, 25, 19, 728)  536536      block8_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block8_sepconv3_bn (BatchNormal (None, 25, 19, 728)  2912        block8_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_42 (Add)                    (None, 25, 19, 728)  0           block8_sepconv3_bn[0][0]         \n","                                                                 add_41[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1_act (Activation (None, 25, 19, 728)  0           add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block9_sepconv1 (SeparableConv2 (None, 25, 19, 728)  536536      block9_sepconv1_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv1_bn (BatchNormal (None, 25, 19, 728)  2912        block9_sepconv1[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv2_act (Activation (None, 25, 19, 728)  0           block9_sepconv1_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv2 (SeparableConv2 (None, 25, 19, 728)  536536      block9_sepconv2_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv2_bn (BatchNormal (None, 25, 19, 728)  2912        block9_sepconv2[0][0]            \n","__________________________________________________________________________________________________\n","block9_sepconv3_act (Activation (None, 25, 19, 728)  0           block9_sepconv2_bn[0][0]         \n","__________________________________________________________________________________________________\n","block9_sepconv3 (SeparableConv2 (None, 25, 19, 728)  536536      block9_sepconv3_act[0][0]        \n","__________________________________________________________________________________________________\n","block9_sepconv3_bn (BatchNormal (None, 25, 19, 728)  2912        block9_sepconv3[0][0]            \n","__________________________________________________________________________________________________\n","add_43 (Add)                    (None, 25, 19, 728)  0           block9_sepconv3_bn[0][0]         \n","                                                                 add_42[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1_act (Activatio (None, 25, 19, 728)  0           add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block10_sepconv1 (SeparableConv (None, 25, 19, 728)  536536      block10_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv1_bn (BatchNorma (None, 25, 19, 728)  2912        block10_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv2_act (Activatio (None, 25, 19, 728)  0           block10_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv2 (SeparableConv (None, 25, 19, 728)  536536      block10_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv2_bn (BatchNorma (None, 25, 19, 728)  2912        block10_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block10_sepconv3_act (Activatio (None, 25, 19, 728)  0           block10_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block10_sepconv3 (SeparableConv (None, 25, 19, 728)  536536      block10_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block10_sepconv3_bn (BatchNorma (None, 25, 19, 728)  2912        block10_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_44 (Add)                    (None, 25, 19, 728)  0           block10_sepconv3_bn[0][0]        \n","                                                                 add_43[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1_act (Activatio (None, 25, 19, 728)  0           add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block11_sepconv1 (SeparableConv (None, 25, 19, 728)  536536      block11_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv1_bn (BatchNorma (None, 25, 19, 728)  2912        block11_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv2_act (Activatio (None, 25, 19, 728)  0           block11_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv2 (SeparableConv (None, 25, 19, 728)  536536      block11_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv2_bn (BatchNorma (None, 25, 19, 728)  2912        block11_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block11_sepconv3_act (Activatio (None, 25, 19, 728)  0           block11_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block11_sepconv3 (SeparableConv (None, 25, 19, 728)  536536      block11_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block11_sepconv3_bn (BatchNorma (None, 25, 19, 728)  2912        block11_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_45 (Add)                    (None, 25, 19, 728)  0           block11_sepconv3_bn[0][0]        \n","                                                                 add_44[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1_act (Activatio (None, 25, 19, 728)  0           add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block12_sepconv1 (SeparableConv (None, 25, 19, 728)  536536      block12_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv1_bn (BatchNorma (None, 25, 19, 728)  2912        block12_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv2_act (Activatio (None, 25, 19, 728)  0           block12_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv2 (SeparableConv (None, 25, 19, 728)  536536      block12_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv2_bn (BatchNorma (None, 25, 19, 728)  2912        block12_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block12_sepconv3_act (Activatio (None, 25, 19, 728)  0           block12_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","block12_sepconv3 (SeparableConv (None, 25, 19, 728)  536536      block12_sepconv3_act[0][0]       \n","__________________________________________________________________________________________________\n","block12_sepconv3_bn (BatchNorma (None, 25, 19, 728)  2912        block12_sepconv3[0][0]           \n","__________________________________________________________________________________________________\n","add_46 (Add)                    (None, 25, 19, 728)  0           block12_sepconv3_bn[0][0]        \n","                                                                 add_45[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1_act (Activatio (None, 25, 19, 728)  0           add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_sepconv1 (SeparableConv (None, 25, 19, 728)  536536      block13_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv1_bn (BatchNorma (None, 25, 19, 728)  2912        block13_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block13_sepconv2_act (Activatio (None, 25, 19, 728)  0           block13_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block13_sepconv2 (SeparableConv (None, 25, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","block13_sepconv2_bn (BatchNorma (None, 25, 19, 1024) 4096        block13_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","conv2d_15 (Conv2D)              (None, 13, 10, 1024) 745472      add_46[0][0]                     \n","__________________________________________________________________________________________________\n","block13_pool (MaxPooling2D)     (None, 13, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_15 (BatchNo (None, 13, 10, 1024) 4096        conv2d_15[0][0]                  \n","__________________________________________________________________________________________________\n","add_47 (Add)                    (None, 13, 10, 1024) 0           block13_pool[0][0]               \n","                                                                 batch_normalization_15[0][0]     \n","__________________________________________________________________________________________________\n","block14_sepconv1 (SeparableConv (None, 13, 10, 1536) 1582080     add_47[0][0]                     \n","__________________________________________________________________________________________________\n","block14_sepconv1_bn (BatchNorma (None, 13, 10, 1536) 6144        block14_sepconv1[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv1_act (Activatio (None, 13, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n","__________________________________________________________________________________________________\n","block14_sepconv2 (SeparableConv (None, 13, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n","__________________________________________________________________________________________________\n","block14_sepconv2_bn (BatchNorma (None, 13, 10, 2048) 8192        block14_sepconv2[0][0]           \n","__________________________________________________________________________________________________\n","block14_sepconv2_act (Activatio (None, 13, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n","__________________________________________________________________________________________________\n","dropout_6 (Dropout)             (None, 13, 10, 2048) 0           block14_sepconv2_act[0][0]       \n","__________________________________________________________________________________________________\n","global_average_pooling2d_3 (Glo (None, 2048)         0           dropout_6[0][0]                  \n","__________________________________________________________________________________________________\n","dense_6 (Dense)                 (None, 64)           131136      global_average_pooling2d_3[0][0] \n","__________________________________________________________________________________________________\n","dropout_7 (Dropout)             (None, 64)           0           dense_6[0][0]                    \n","__________________________________________________________________________________________________\n","dense_7 (Dense)                 (None, 12)           780         dropout_7[0][0]                  \n","==================================================================================================\n","Total params: 20,993,396\n","Trainable params: 3,295,564\n","Non-trainable params: 17,697,832\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HEO6gEONGo4Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":984},"outputId":"d292960b-e517-4433-e0d5-83da6397bbf3","executionInfo":{"status":"ok","timestamp":1575980074373,"user_tz":-330,"elapsed":2929394,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["model.fit_generator(train,epochs=10,validation_data=val,callbacks=[checkpointer,lrReducer])"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","274/275 [============================>.] - ETA: 1s - loss: 1.3953 - acc: 0.5640Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:32 - loss: 1.8869 - acc: 0.4550\n","Epoch 00001: val_acc improved from -inf to 0.45495, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last4-64affine-Adam-wAugmentation-weights.hdf5\n","275/275 [==============================] - 337s 1s/step - loss: 1.3946 - acc: 0.5643 - val_loss: 1.8869 - val_acc: 0.4550\n","Epoch 2/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.8743 - acc: 0.7355Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:11 - loss: 2.0229 - acc: 0.4257\n","Epoch 00002: val_acc did not improve from 0.45495\n","275/275 [==============================] - 288s 1s/step - loss: 0.8735 - acc: 0.7356 - val_loss: 2.0229 - val_acc: 0.4257\n","Epoch 3/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.7020 - acc: 0.7852Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:11 - loss: 2.1660 - acc: 0.4054\n","Epoch 00003: val_acc did not improve from 0.45495\n","275/275 [==============================] - 292s 1s/step - loss: 0.7015 - acc: 0.7856 - val_loss: 2.1660 - val_acc: 0.4054\n","Epoch 4/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.5811 - acc: 0.8215Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:10 - loss: 2.0588 - acc: 0.4820\n","Epoch 00004: val_acc improved from 0.45495 to 0.48198, saving model to /content/gdrive/My Drive/Colab Notebooks/chkpts/imagenet-last4-64affine-Adam-wAugmentation-weights.hdf5\n","275/275 [==============================] - 292s 1s/step - loss: 0.5812 - acc: 0.8211 - val_loss: 2.0588 - val_acc: 0.4820\n","Epoch 5/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.4978 - acc: 0.8491Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:04 - loss: 2.3596 - acc: 0.4234\n","Epoch 00005: val_acc did not improve from 0.48198\n","275/275 [==============================] - 285s 1s/step - loss: 0.4976 - acc: 0.8491 - val_loss: 2.3596 - val_acc: 0.4234\n","Epoch 6/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8640Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:10 - loss: 2.1243 - acc: 0.4572\n","Epoch 00006: val_acc did not improve from 0.48198\n","275/275 [==============================] - 288s 1s/step - loss: 0.4468 - acc: 0.8641 - val_loss: 2.1243 - val_acc: 0.4572\n","Epoch 7/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.4041 - acc: 0.8766Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:10 - loss: 2.3271 - acc: 0.4099\n","Epoch 00007: val_acc did not improve from 0.48198\n","275/275 [==============================] - 289s 1s/step - loss: 0.4037 - acc: 0.8768 - val_loss: 2.3271 - val_acc: 0.4099\n","Epoch 8/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.3607 - acc: 0.8922Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:06 - loss: 2.4769 - acc: 0.4122\n","Epoch 00008: val_acc did not improve from 0.48198\n","275/275 [==============================] - 286s 1s/step - loss: 0.3610 - acc: 0.8920 - val_loss: 2.4769 - val_acc: 0.4122\n","Epoch 9/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9088Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:03 - loss: 2.2948 - acc: 0.4527\n","Epoch 00009: val_acc did not improve from 0.48198\n","275/275 [==============================] - 286s 1s/step - loss: 0.3112 - acc: 0.9088 - val_loss: 2.2948 - val_acc: 0.4527\n","Epoch 10/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.2940 - acc: 0.9127Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:00 - loss: 2.4778 - acc: 0.4347\n","Epoch 00010: val_acc did not improve from 0.48198\n","275/275 [==============================] - 281s 1s/step - loss: 0.2938 - acc: 0.9128 - val_loss: 2.4778 - val_acc: 0.4347\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc81e825208>"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"code","metadata":{"id":"4bhYa3cuGtDS","colab_type":"code","colab":{}},"source":["#since the model curved up at 9 th epoch i decided to run it for a few more epochs...\n","model.load_weights(os.path.join(chkpt_dir,\"imagenet-last8-64affine-Adam-wAugmentation-weights.hdf5\"))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4IMS97l4Ylq0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":964},"outputId":"9f66d3ca-0721-47f1-cea8-1a2fa80e78f7","executionInfo":{"status":"ok","timestamp":1575977106234,"user_tz":-330,"elapsed":2839801,"user":{"displayName":"Singh Akhil","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mA36AceXWq_HrzeD0O1PmRhh5A07fstsh9aa4qxFA=s64","userId":"03591970807351555446"}}},"source":["model.fit_generator(train,epochs=10,validation_data=val,callbacks=[checkpointer,lrReducer])"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Epoch 1/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9552Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:04 - loss: 2.2656 - acc: 0.5090\n","Epoch 00001: val_acc did not improve from 0.55405\n","275/275 [==============================] - 290s 1s/step - loss: 0.1604 - acc: 0.9550 - val_loss: 2.2656 - val_acc: 0.5090\n","Epoch 2/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9627Epoch 1/10\n"," 14/275 [>.............................] - ETA: 5:53 - loss: 2.1538 - acc: 0.5518\n","Epoch 00002: val_acc did not improve from 0.55405\n","275/275 [==============================] - 280s 1s/step - loss: 0.1395 - acc: 0.9626 - val_loss: 2.1538 - val_acc: 0.5518\n","Epoch 3/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9656Epoch 1/10\n"," 14/275 [>.............................] - ETA: 5:56 - loss: 2.2399 - acc: 0.5383\n","Epoch 00003: val_acc did not improve from 0.55405\n","275/275 [==============================] - 282s 1s/step - loss: 0.1270 - acc: 0.9654 - val_loss: 2.2399 - val_acc: 0.5383\n","Epoch 4/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9639Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:02 - loss: 2.4276 - acc: 0.5248\n","Epoch 00004: val_acc did not improve from 0.55405\n","275/275 [==============================] - 281s 1s/step - loss: 0.1292 - acc: 0.9639 - val_loss: 2.4276 - val_acc: 0.5248\n","Epoch 5/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9673Epoch 1/10\n"," 14/275 [>.............................] - ETA: 5:56 - loss: 2.2429 - acc: 0.5383\n","Epoch 00005: val_acc did not improve from 0.55405\n","275/275 [==============================] - 283s 1s/step - loss: 0.1207 - acc: 0.9673 - val_loss: 2.2429 - val_acc: 0.5383\n","Epoch 6/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9744Epoch 1/10\n"," 14/275 [>.............................] - ETA: 5:55 - loss: 2.3773 - acc: 0.5023\n","Epoch 00006: val_acc did not improve from 0.55405\n","275/275 [==============================] - 284s 1s/step - loss: 0.0992 - acc: 0.9743 - val_loss: 2.3773 - val_acc: 0.5023\n","Epoch 7/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9735Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:01 - loss: 2.4300 - acc: 0.5180\n","Epoch 00007: val_acc did not improve from 0.55405\n","275/275 [==============================] - 283s 1s/step - loss: 0.1026 - acc: 0.9735 - val_loss: 2.4300 - val_acc: 0.5180\n","Epoch 8/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9784Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:00 - loss: 2.3219 - acc: 0.5248\n","Epoch 00008: val_acc did not improve from 0.55405\n","275/275 [==============================] - 284s 1s/step - loss: 0.0857 - acc: 0.9784 - val_loss: 2.3219 - val_acc: 0.5248\n","Epoch 9/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9777Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:04 - loss: 2.8350 - acc: 0.5180\n","Epoch 00009: val_acc did not improve from 0.55405\n","275/275 [==============================] - 286s 1s/step - loss: 0.0822 - acc: 0.9775 - val_loss: 2.8350 - val_acc: 0.5180\n","Epoch 10/10\n","274/275 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9758Epoch 1/10\n"," 14/275 [>.............................] - ETA: 6:10 - loss: 2.6261 - acc: 0.5405\n","Epoch 00010: val_acc did not improve from 0.55405\n","275/275 [==============================] - 287s 1s/step - loss: 0.0831 - acc: 0.9759 - val_loss: 2.6261 - val_acc: 0.5405\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc81e7c8940>"]},"metadata":{"tags":[]},"execution_count":40}]},{"cell_type":"code","metadata":{"id":"IHcupvL-YuWE","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}